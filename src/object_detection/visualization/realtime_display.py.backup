import cv2
import yaml
import numpy as np
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import logging

from .map_canvas import MapCanvas
from ..mapping.homography import HomographyCalculator
from ..mapping.object_mapper import ObjectMapper

class RealtimeDisplay:
   """Coordinates side-by-side video tracking and 2D map visualization"""
   
   def __init__(self, config_path: str = "configs/visualization/realtime.yaml"):
       """Initialize realtime display system"""
       self.config = self._load_config(config_path)
       
       # Initialize map canvas
       canvas_config = self.config['visualization']['canvas']
       world_bounds = tuple(self.config['visualization']['world_bounds'])
       
       self.map_canvas = MapCanvas(
           width=canvas_config['width'],
           height=canvas_config['height'],
           world_bounds=world_bounds,
           background_color=tuple(canvas_config['background_color'])
       )
       
       # Display settings
       display_config = self.config['visualization']['display']
       self.video_window = display_config['window_names']['video']
       self.map_window = display_config['window_names']['map']
       
       # Performance tracking
       self.frame_count = 0
       self.cleanup_interval = self.config['visualization']['performance']['trail_cleanup_interval']
       
       # Setup logging
       self.logger = logging.getLogger(__name__)
       
   def _load_config(self, config_path: str) -> Dict:
       """Load visualization configuration"""
       with open(config_path, 'r') as f:
           return yaml.safe_load(f)
   
   def setup_windows(self):
       """Initialize OpenCV display windows"""
       cv2.namedWindow(self.video_window, cv2.WINDOW_NORMAL)
       cv2.namedWindow(self.map_window, cv2.WINDOW_NORMAL)
       
       # Position windows side by side
       cv2.moveWindow(self.video_window, 100, 100)
       cv2.moveWindow(self.map_window, 800, 100)
       
       self.logger.info(f"Display windows initialized: {self.video_window}, {self.map_window}")
   
   def update_displays(self, video_frame: np.ndarray, detections: List[Dict], 
                      homography_calculator: HomographyCalculator):
       """Update both video and map displays with current detections"""
       
       # Update map with transformed coordinates
       for detection in detections:
           track_id = detection['track_id']
           pixel_x = detection['pixel_x']
           pixel_y = detection['pixel_y']
           class_name = detection['class_name']
           confidence = detection['confidence']
           
           # Transform to world coordinates
           world_x, world_y = homography_calculator.transform_point(pixel_x, pixel_y)
           
           # Update map canvas
           self.map_canvas.update_object(
               track_id=track_id,
               world_x=world_x,
               world_y=world_y,
               class_name=class_name,
               confidence=confidence
           )
       
       # Render map
       map_frame = self.map_canvas.render(
           show_trails=self.config['visualization']['trails']['enabled'],
           show_grid=self.config['visualization']['grid']['enabled']
       )
       
       # Add coordinate info to map
       self._add_coordinate_info(map_frame)
       
       # Display both frames
       cv2.imshow(self.video_window, video_frame)
       cv2.imshow(self.map_window, map_frame)
       
       # Periodic cleanup
       self.frame_count += 1
       if self.frame_count % self.cleanup_interval == 0:
           self._cleanup_old_tracks(detections)
   
   def _add_coordinate_info(self, map_frame: np.ndarray):
       """Add coordinate system info to map display"""
       bounds = self.config['visualization']['world_bounds']
       
       # Add coordinate labels
       cv2.putText(map_frame, f"World Bounds: ({bounds[0]:.1f}, {bounds[1]:.1f}) to ({bounds[2]:.1f}, {bounds[3]:.1f})", 
                  (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
       
       cv2.putText(map_frame, f"Frame: {self.frame_count}", 
                  (10, map_frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
   
   def _cleanup_old_tracks(self, current_detections: List[Dict]):
       """Remove tracks that are no longer being detected"""
       current_track_ids = {det['track_id'] for det in current_detections}
       
       # Remove old tracks from map canvas
       tracks_to_remove = []
       for track_id in self.map_canvas.trails.keys():
           if track_id not in current_track_ids:
               tracks_to_remove.append(track_id)
       
       for track_id in tracks_to_remove:
           self.map_canvas.remove_track(track_id)
       
       if tracks_to_remove:
           self.logger.debug(f"Cleaned up {len(tracks_to_remove)} old tracks")
   
   def process_video_realtime(self, object_mapper: ObjectMapper, video_source: str, 
                             show_fps: bool = True) -> bool:
       """
       Process video with real-time side-by-side display
       
       Args:
           object_mapper: Configured ObjectMapper instance
           video_source: Path to video file or camera index
           show_fps: Whether to display FPS counter
           
       Returns:
           bool: True if processing completed successfully
       """
       # Setup display windows
       self.setup_windows()
       
       # Open video source
       cap = cv2.VideoCapture(video_source)
       if not cap.isOpened():
           self.logger.error(f"Failed to open video source: {video_source}")
           return False
       
       fps = cap.get(cv2.CAP_PROP_FPS) or 30
       frame_delay = int(1000 / fps)  # milliseconds
       
       try:
           while True:
               ret, frame = cap.read()
               if not ret:
                   self.logger.info("Video processing completed")
                   break
               
               # Get detections from object mapper
               detections = object_mapper._process_frame(frame)
               
               # Draw detections on video frame
               annotated_frame = self._annotate_video_frame(frame, detections)
               
               # Add FPS counter if requested
               if show_fps:
                   cv2.putText(annotated_frame, f"FPS: {fps:.1f}", 
                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
               
               # Update both displays
               self.update_displays(annotated_frame, detections, object_mapper.homography_calculator)
               
               # Check for exit
               key = cv2.waitKey(frame_delay) & 0xFF
               if key == ord('q') or key == 27:  # 'q' or ESC
                   self.logger.info("User requested exit")
                   break
               elif key == ord('c'):  # 'c' to clear trails
                   self.map_canvas.clear_trails()
                   self.logger.info("Trails cleared")
       
       finally:
           cap.release()
           cv2.destroyAllWindows()
           self.logger.info("Realtime display cleanup completed")
       
       return True
   
   def _annotate_video_frame(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:
       """Add detection annotations to video frame"""
       annotated = frame.copy()
       
       for detection in detections:
           # Extract detection info
           x1, y1, x2, y2 = detection['bbox']
           track_id = detection['track_id']
           class_name = detection['class_name']
           confidence = detection['confidence']
           
           # Get consistent color for track
           color = self.map_canvas.get_track_color(track_id)
           
           # Draw bounding box
           cv2.rectangle(annotated, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
           
           # Draw label
           label = f"ID:{track_id} {class_name} {confidence:.2f}"
           label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
           
           cv2.rectangle(annotated, 
                        (int(x1), int(y1) - label_size[1] - 10), 
                        (int(x1) + label_size[0], int(y1)), 
                        color, -1)
           
           cv2.putText(annotated, label, 
                      (int(x1), int(y1) - 5), 
                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
       
       return annotated
   
   def close(self):
       """Clean up resources"""
       cv2.destroyAllWindows()
       self.logger.info("RealtimeDisplay closed")
